{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reshaping, stacking, squeezing and unsqueezing, and indexing tensors\n\n- reashape : to reshape a tensor to a different shape\n- view : returns the view of an tensor but keep the memory same as original tensor\n- stacking : combining multiple tensors on top of each other (vstack) or side by side (hstack)\n- squeeze : remove all (1) dimensions from a tensor\n- unsqueeze : add (1) dimensions from a tensor\n- permute : return the view of a tensor with dimensions permuted(swapped) in a certain way\n- use indexes to find any element from n-dimensional array\n","metadata":{}},{"cell_type":"code","source":"# importing\ntry:\n    import torch\n    import numpy\n    import matplotlib.pyplot as plt\n    print(\"Done Successfully\")\nexcept Exception as e:\n    print(\"Failed to import\",e)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:25:21.703904Z","iopub.execute_input":"2026-01-05T13:25:21.704307Z","iopub.status.idle":"2026-01-05T13:25:26.629383Z","shell.execute_reply.started":"2026-01-05T13:25:21.704273Z","shell.execute_reply":"2026-01-05T13:25:26.627945Z"}},"outputs":[{"name":"stdout","text":"Done Successfully\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Reshape\nt1= torch.rand([3,4])\n\n#now we can reshape this tensor in all the ways the multiple of rows and columns remains constant  \nreshape1=t1.reshape([4,3])\nreshape2=t1.reshape([2,2,3])\nprint(t1)\nprint(reshape1)\nprint(reshape2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:25:26.631361Z","iopub.execute_input":"2026-01-05T13:25:26.631856Z","iopub.status.idle":"2026-01-05T13:25:26.746616Z","shell.execute_reply.started":"2026-01-05T13:25:26.631826Z","shell.execute_reply":"2026-01-05T13:25:26.745639Z"}},"outputs":[{"name":"stdout","text":"tensor([[0.8004, 0.2613, 0.8922, 0.4527],\n        [0.9110, 0.6610, 0.0518, 0.9074],\n        [0.8437, 0.5873, 0.2867, 0.6249]])\ntensor([[0.8004, 0.2613, 0.8922],\n        [0.4527, 0.9110, 0.6610],\n        [0.0518, 0.9074, 0.8437],\n        [0.5873, 0.2867, 0.6249]])\ntensor([[[0.8004, 0.2613, 0.8922],\n         [0.4527, 0.9110, 0.6610]],\n\n        [[0.0518, 0.9074, 0.8437],\n         [0.5873, 0.2867, 0.6249]]])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# view: same concept as in pthon, used to create a copy sharing the same memory location, change its value and you change the original too\n\nts=torch.arange(1,11)\n\ntv=ts.view(10) #input shape to view in \ntv1=ts.view(5,2)\n\n\nprint(\"original tensor:\",ts)\nprint(\"viewing in original shape:\",tv)\nprint(\"viewing in changed shape:\",tv1)\n\n\n# now change the values of tv/tv1 and see what happens to ts\ntv[0]=20\nprint(\"value of tv\",tv)\nprint(\"notice the changed original value ts\",ts)\nprint(\"also tv1:\",tv1) # notice changed value of another derived tensor too\n\ntv=torch.arange(1,6) # I did a great mistake here -tv points to a new tensor, ts is untouched and the old view relationship is gone.\nprint(\"this is ts:\",ts) \nprint(\"this is tv\", tv) #notice unchanged value of ts ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:34:00.009961Z","iopub.execute_input":"2026-01-05T13:34:00.010425Z","iopub.status.idle":"2026-01-05T13:34:00.021110Z","shell.execute_reply.started":"2026-01-05T13:34:00.010391Z","shell.execute_reply":"2026-01-05T13:34:00.020159Z"}},"outputs":[{"name":"stdout","text":"original tensor: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nviewing in original shape: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nviewing in changed shape: tensor([[ 1,  2],\n        [ 3,  4],\n        [ 5,  6],\n        [ 7,  8],\n        [ 9, 10]])\nvalue of tv tensor([20,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nnotice the changed original value ts tensor([20,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nalso tv1: tensor([[20,  2],\n        [ 3,  4],\n        [ 5,  6],\n        [ 7,  8],\n        [ 9, 10]])\nthis is ts: tensor([20,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nthis is tv tensor([1, 2, 3, 4, 5])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# stacking\nt=torch.tensor([1,2,3])\nt2=torch.tensor([4,5,6])\nprint(t)\n\nx=torch.stack([t,t2],dim=0)\nprint(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:25:26.773404Z","iopub.status.idle":"2026-01-05T13:25:26.773745Z","shell.execute_reply.started":"2026-01-05T13:25:26.773598Z","shell.execute_reply":"2026-01-05T13:25:26.773617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Squeezing : remove one fake dimension\n\nx=torch.rand([1,4,1])\nprint(x)\n\ny=x.squeeze() #removes all 1 dims\nprint(y)\n\ny1=x.squeeze(0) #removes 1 dim at 0th index \nprint(y1)\n\ny2=x.squeeze(2) #removes 1 dim at 2nd index \nprint(y2)\n\ny3=x.squeeze(1) #see there is no 1 dim at 1st index, so it does nothing\nprint(y3)\n\n\nprint(x.size(), y1.size(), y2.size(), y3.size()) #remains same size as of original\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:25:26.775358Z","iopub.status.idle":"2026-01-05T13:25:26.775736Z","shell.execute_reply.started":"2026-01-05T13:25:26.775589Z","shell.execute_reply":"2026-01-05T13:25:26.775608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unsqueezing : adds a fake dimension, make sure unsqueeze(n) always has an argument\nx=torch.rand([2,3])\nprint(x)\n\nx1=x.unsqueeze(0) # add one dim at 0th index \nprint(x1)\n\nx2=x.unsqueeze(1) # add one dim at 1st index\nprint(x2)\n\nx3=x.unsqueeze(2) # add one dim at 2nd index\nprint(x3)\n\nprint(x.size(), x1.size(), x2.size(), x3.size())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:25:26.777569Z","iopub.status.idle":"2026-01-05T13:25:26.777911Z","shell.execute_reply.started":"2026-01-05T13:25:26.777772Z","shell.execute_reply":"2026-01-05T13:25:26.777790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Permute\ntest= torch.rand(size=(144,144,3))\nptest=test.permute(0,2,1)\n\nprint(test.size())\nprint(ptest.size()) # the 0tth and 2nd indexes are swapped \n\ntest=torch.rand(size=(1,2,2))\nptest=test.permute(0,2,1) #swapping 2nd and 1st index\n\nprint(test.size())\nprint(ptest.size()) # the indexes are swapped \n\n# comparing the data:\nprint(test)\nprint(ptest)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T13:25:26.779542Z","iopub.status.idle":"2026-01-05T13:25:26.779860Z","shell.execute_reply.started":"2026-01-05T13:25:26.779721Z","shell.execute_reply":"2026-01-05T13:25:26.779739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2D- indexing \nx =torch.arange(1,10).reshape([3,3])\nprint(x)\n\nprint(\"first row\",x[0]) # find first row\nprint(\"second row\",x[1]) # find second row\n\nprint(\"first column\",x[:,0]) # print first column\n\n\nprint(\"first element:\",x[0,0])\n\nprint(\"r1 c3\",x[0,2])\nprint(\"r2 c2\",x[1,1])\n\n# 3D- indexing\ny=torch.stack([x,x]) #stacking x above x to get a 3d- tensor\nprint(y) #see our tensor\nprint(\"dimension of y:\",y.dim()) #check the dim to confirm 3-d conversion\nprint(\"shape of y:\",y.shape) # check shape to know your boundaries\n\nprint(\"element at 0th index in y\",y[0]) #prints tensor x \nprint(\"element in [1,1,1]\",y[1,1,1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T14:00:22.853145Z","iopub.execute_input":"2026-01-05T14:00:22.853513Z","iopub.status.idle":"2026-01-05T14:00:22.864957Z","shell.execute_reply.started":"2026-01-05T14:00:22.853483Z","shell.execute_reply":"2026-01-05T14:00:22.864008Z"}},"outputs":[{"name":"stdout","text":"tensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])\nfirst row tensor([1, 2, 3])\nsecond row tensor([4, 5, 6])\nfirst column tensor([1, 4, 7])\nfirst element: tensor(1)\nr1 c3 tensor(3)\nr2 c2 tensor(5)\ntensor([[[1, 2, 3],\n         [4, 5, 6],\n         [7, 8, 9]],\n\n        [[1, 2, 3],\n         [4, 5, 6],\n         [7, 8, 9]]])\ndimension of y: 3\nshape of y: torch.Size([2, 3, 3])\nelement at 0th index in y tensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])\nelement in [1,1,1] tensor(5)\n","output_type":"stream"}],"execution_count":30}]}